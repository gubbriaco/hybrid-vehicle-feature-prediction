{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc0fb09c-5748-4bb0-a640-cde28de380c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in d:\\virtualenv\\myenv\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (70.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in d:\\virtualenv\\myenv\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in d:\\virtualenv\\myenv\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in d:\\virtualenv\\myenv\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\virtualenv\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\virtualenv\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\virtualenv\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\virtualenv\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2024.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\virtualenv\\myenv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\virtualenv\\myenv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e312a512-0373-4f02-acab-60115b88ad8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\giorg\\AppData\\Local\\Temp\\ipykernel_19216\\3326022288.py:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f46f174c-7918-458f-ac6d-079f5bdbe198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 14515549611836497348\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e9eb670-162c-4028-9ff5-b7a962c4526d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\virtualenv\\myenv\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in d:\\virtualenv\\myenv\\lib\\site-packages (from pandas) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\virtualenv\\myenv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\virtualenv\\myenv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\virtualenv\\myenv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\virtualenv\\myenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f358af3-c925-4122-86a5-f7ea8bf6f1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in d:\\virtualenv\\myenv\\lib\\site-packages (3.9.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\virtualenv\\myenv\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\virtualenv\\myenv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from matplotlib) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\virtualenv\\myenv\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.23 in d:\\virtualenv\\myenv\\lib\\site-packages (from matplotlib) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in d:\\virtualenv\\myenv\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\virtualenv\\myenv\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\virtualenv\\myenv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\virtualenv\\myenv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6701d76-4b48-474b-b828-85e1c396cf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from config import Config\n",
    "from utils import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe268446-8845-454d-8d41-4ba18eaa94a4",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f181568a-b11c-4e52-9d3b-c1cb45956826",
   "metadata": {},
   "source": [
    "## Paths Declaration\n",
    "Qui, di seguito, vengono riportati i path relativi al dataset di training, validation e testing. In particolare, il dataset di validation coincide con il primo dataset di testing contenuto nella cartella './LGHG2@n10C_to_25degC/Test'. Infatti, all'interno della directory './LGHG2@n10C_to_25degC/Test' sono presenti 5 possibili insiemi di dati così da poter essere sfruttati durante il testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e9d8c39-735e-4b20-91e7-a05a4b424844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_dir = ['test', 'train', 'val']\n",
      "train_data_dir = ['TRAIN_LGHG2@n10degC_to_25degC_Norm_5Inputs.csv']\n",
      "val_data_dir = ['01_TEST_LGHG2@n10degC_Norm_(05_Inputs).csv', '02_TEST_LGHG2@0degC_Norm_(05_Inputs).csv', '03_TEST_LGHG2@10degC_Norm_(05_Inputs).csv', '04_TEST_LGHG2@25degC_Norm_(05_Inputs).csv']\n",
      "test_data_dir = ['01_TEST_LGHG2@n10degC_Norm_(05_Inputs).csv', '02_TEST_LGHG2@0degC_Norm_(05_Inputs).csv', '03_TEST_LGHG2@10degC_Norm_(05_Inputs).csv', '04_TEST_LGHG2@25degC_Norm_(05_Inputs).csv']\n"
     ]
    }
   ],
   "source": [
    "config = Config(\n",
    "    data_dir='./data',\n",
    "    train_data_subdir='train/',\n",
    "    val_data_subdir='test/',\n",
    "    test_data_subdir='test/'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dee037-7f18-4047-85cc-908f2db39220",
   "metadata": {},
   "source": [
    "# Data Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78a282f4-2653-4037-ac2b-75216df36724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V</th>\n",
       "      <th>I</th>\n",
       "      <th>Temp</th>\n",
       "      <th>V_avg</th>\n",
       "      <th>I_avg</th>\n",
       "      <th>SOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.385148</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.303101</td>\n",
       "      <td>0.385148</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.206417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.385152</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.304591</td>\n",
       "      <td>0.385150</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.206417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.385156</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.306081</td>\n",
       "      <td>0.385152</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.206417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.385160</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.307572</td>\n",
       "      <td>0.385154</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.206417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.385164</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.309062</td>\n",
       "      <td>0.385156</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.206417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669951</th>\n",
       "      <td>0.478843</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.008477</td>\n",
       "      <td>0.459558</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.283243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669952</th>\n",
       "      <td>0.478843</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.008477</td>\n",
       "      <td>0.459699</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.283243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669953</th>\n",
       "      <td>0.478843</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.008477</td>\n",
       "      <td>0.459839</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.283243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669954</th>\n",
       "      <td>0.478961</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.008477</td>\n",
       "      <td>0.459979</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.283243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669955</th>\n",
       "      <td>0.478961</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.008477</td>\n",
       "      <td>0.460117</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.283243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>669956 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               V        I      Temp     V_avg    I_avg       SOC\n",
       "0       0.385148  0.75102  0.303101  0.385148  0.75102  0.206417\n",
       "1       0.385152  0.75102  0.304591  0.385150  0.75102  0.206417\n",
       "2       0.385156  0.75102  0.306081  0.385152  0.75102  0.206417\n",
       "3       0.385160  0.75102  0.307572  0.385154  0.75102  0.206417\n",
       "4       0.385164  0.75102  0.309062  0.385156  0.75102  0.206417\n",
       "...          ...      ...       ...       ...      ...       ...\n",
       "669951  0.478843  0.75102  0.008477  0.459558  0.75102  0.283243\n",
       "669952  0.478843  0.75102  0.008477  0.459699  0.75102  0.283243\n",
       "669953  0.478843  0.75102  0.008477  0.459839  0.75102  0.283243\n",
       "669954  0.478961  0.75102  0.008477  0.459979  0.75102  0.283243\n",
       "669955  0.478961  0.75102  0.008477  0.460117  0.75102  0.283243\n",
       "\n",
       "[669956 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_filename = os.listdir(config.get_train_data_dir())[0]\n",
    "train_data_path = os.path.join(config.get_train_data_dir(), train_data_filename)\n",
    "\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8da13fa7-413c-411c-b816-064757dc8140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V', 'I', 'Temp', 'V_avg', 'I_avg', 'SOC'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ceb8e614-11b7-4453-a338-c71839d81f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(669956, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_data[['V', 'I', 'Temp', 'V_avg', 'I_avg']].values\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90a89c18-d17c-41e2-8361-caaa9921976f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38514793, 0.75102009, 0.30310108, 0.38514793, 0.75102009],\n",
       "       [0.38515183, 0.75102009, 0.30459129, 0.38514988, 0.75102009],\n",
       "       [0.38515573, 0.75102009, 0.3060815 , 0.38515183, 0.75102009],\n",
       "       ...,\n",
       "       [0.47884278, 0.75102009, 0.00847709, 0.45983939, 0.75102009],\n",
       "       [0.4789612 , 0.75102009, 0.00847709, 0.45997861, 0.75102009],\n",
       "       [0.4789612 , 0.75102009, 0.00847709, 0.46011672, 0.75102009]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e396bbb2-14c7-4637-8ad2-1d5170af5b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(669956,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train_data['SOC'].values\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fb36c47-8b7f-4ed9-b58b-c90413322b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20641667, 0.20641667, 0.20641667, ..., 0.28324333, 0.28324333,\n",
       "       0.28324333])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e343c7c-ffb1-40ae-a091-592fcc1f6fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V</th>\n",
       "      <th>I</th>\n",
       "      <th>Temp</th>\n",
       "      <th>V_avg</th>\n",
       "      <th>I_avg</th>\n",
       "      <th>SOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.966960</td>\n",
       "      <td>0.748900</td>\n",
       "      <td>0.920678</td>\n",
       "      <td>0.966960</td>\n",
       "      <td>0.748900</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.966020</td>\n",
       "      <td>0.746992</td>\n",
       "      <td>0.920677</td>\n",
       "      <td>0.966490</td>\n",
       "      <td>0.747946</td>\n",
       "      <td>0.999990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.965901</td>\n",
       "      <td>0.746992</td>\n",
       "      <td>0.917845</td>\n",
       "      <td>0.966294</td>\n",
       "      <td>0.747628</td>\n",
       "      <td>0.999983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.965783</td>\n",
       "      <td>0.747098</td>\n",
       "      <td>0.917845</td>\n",
       "      <td>0.966166</td>\n",
       "      <td>0.747496</td>\n",
       "      <td>0.999973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.746992</td>\n",
       "      <td>0.917845</td>\n",
       "      <td>0.966066</td>\n",
       "      <td>0.747395</td>\n",
       "      <td>0.999963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47512</th>\n",
       "      <td>0.298614</td>\n",
       "      <td>0.751020</td>\n",
       "      <td>0.926344</td>\n",
       "      <td>0.292723</td>\n",
       "      <td>0.751020</td>\n",
       "      <td>0.136623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47513</th>\n",
       "      <td>0.298614</td>\n",
       "      <td>0.751020</td>\n",
       "      <td>0.926344</td>\n",
       "      <td>0.292761</td>\n",
       "      <td>0.751020</td>\n",
       "      <td>0.136623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47514</th>\n",
       "      <td>0.298614</td>\n",
       "      <td>0.751020</td>\n",
       "      <td>0.926344</td>\n",
       "      <td>0.292798</td>\n",
       "      <td>0.751020</td>\n",
       "      <td>0.136623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47515</th>\n",
       "      <td>0.298614</td>\n",
       "      <td>0.751020</td>\n",
       "      <td>0.929177</td>\n",
       "      <td>0.292834</td>\n",
       "      <td>0.751020</td>\n",
       "      <td>0.136623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47516</th>\n",
       "      <td>0.298614</td>\n",
       "      <td>0.751020</td>\n",
       "      <td>0.929177</td>\n",
       "      <td>0.292871</td>\n",
       "      <td>0.751020</td>\n",
       "      <td>0.136623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47517 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V         I      Temp     V_avg     I_avg       SOC\n",
       "0      0.966960  0.748900  0.920678  0.966960  0.748900  1.000000\n",
       "1      0.966020  0.746992  0.920677  0.966490  0.747946  0.999990\n",
       "2      0.965901  0.746992  0.917845  0.966294  0.747628  0.999983\n",
       "3      0.965783  0.747098  0.917845  0.966166  0.747496  0.999973\n",
       "4      0.965665  0.746992  0.917845  0.966066  0.747395  0.999963\n",
       "...         ...       ...       ...       ...       ...       ...\n",
       "47512  0.298614  0.751020  0.926344  0.292723  0.751020  0.136623\n",
       "47513  0.298614  0.751020  0.926344  0.292761  0.751020  0.136623\n",
       "47514  0.298614  0.751020  0.926344  0.292798  0.751020  0.136623\n",
       "47515  0.298614  0.751020  0.929177  0.292834  0.751020  0.136623\n",
       "47516  0.298614  0.751020  0.929177  0.292871  0.751020  0.136623\n",
       "\n",
       "[47517 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data_filename = os.listdir(config.get_val_data_dir())[3]\n",
    "val_data_path = os.path.join(config.get_val_data_dir(), val_data_filename)\n",
    "\n",
    "val_data = pd.read_csv(val_data_path)\n",
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9a91c26-3722-4049-b44b-40791e282e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = val_data[['V', 'I', 'Temp', 'V_avg', 'I_avg']].values\n",
    "y_val = val_data['SOC'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc9eb9e-1cd3-4898-89de-f4784ea975fa",
   "metadata": {},
   "source": [
    "## Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efd863c2-d65a-4f68-bb78-cd7d4469c68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.63365322,  1.        , -1.        , -0.63365322,  1.        ],\n",
       "       [-0.63908898,  1.        , -1.        , -0.63909772,  1.        ],\n",
       "       [-0.64456116,  1.        , -1.        , -0.64457869,  1.        ],\n",
       "       ...,\n",
       "       [ 0.26690492,  1.        , -1.        ,  0.21572031,  1.        ],\n",
       "       [ 0.26722387,  1.        , -1.        ,  0.21609528,  1.        ],\n",
       "       [ 0.26722387,  1.        , -1.        ,  0.21646728,  1.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_X_train = normalize(X_train)\n",
    "normalized_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "283ee538-242a-4c7a-a9d6-d20d5aab6809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -1.        ,  0.57551079,  1.        , -1.        ],\n",
       "       [ 0.99571585, -1.        ,  0.58256774,  1.        , -0.99130679],\n",
       "       [ 0.99642139, -1.        ,  0.55815534,  1.        , -0.99419975],\n",
       "       ...,\n",
       "       [-0.98163938,  0.44653221,  1.        , -1.        ,  0.44653221],\n",
       "       [-0.98183573,  0.44006032,  1.        , -1.        ,  0.44006032],\n",
       "       [-0.98194943,  0.44002819,  1.        , -1.        ,  0.44002819]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_X_val = normalize(X_val)\n",
    "normalized_X_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24edad19-e5ed-4041-9be3-858ee2269ffe",
   "metadata": {},
   "source": [
    "# FNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155955d9-48e4-4d9b-a472-952587ee5cfb",
   "metadata": {},
   "source": [
    "## Training Parameters Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0f4f886-17d5-4564-b435-93a3fd59d796",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_features = 5  # Number of inputs features (variables: V, I, Temp, V_avg, I_avg)\n",
    "no_responses = 1  # Number of outputs (SOC)\n",
    "no_hidden_units = 55  # Number of optimal hidden units 'N', where each hidden unit for FNN represents a Neuron.\n",
    "\n",
    "epochs = 50 # Number of epochs\n",
    "no_training = 3 # Number of training execution\n",
    "learn_rate_drop_period = 1000\n",
    "initial_learn_rate = 0.01\n",
    "learn_rate_drop_factor = 0.1\n",
    "validation_frequency = 10\n",
    "mini_batch_size = 32\n",
    "l2_regularization = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e14f30-a647-4edf-8793-e000ca9d2c8c",
   "metadata": {},
   "source": [
    "## FNN Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c60e609f-9a77-4a52-8e5b-1b36481370f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cacd8998-0144-4842-b32a-3ecc1a823893",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainableNormalization(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(TrainableNormalization, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.mean = self.add_weight(\n",
    "            name='mean', \n",
    "            shape=(input_shape[-1],),\n",
    "            initializer='zeros', \n",
    "            trainable=True\n",
    "        )\n",
    "        self.std = self.add_weight(\n",
    "            name='std', \n",
    "            shape=(input_shape[-1],),\n",
    "            initializer='ones', \n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return (inputs - self.mean) / (self.std + keras.backend.epsilon())\n",
    "\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(no_features,)),\n",
    "    layers.Dense(no_hidden_units, activation=keras.activations.tanh),\n",
    "    layers.Dense(no_hidden_units, activation=keras.activations.relu),\n",
    "    layers.Dense(no_responses, activation=keras.activations.sigmoid)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2be3f69-137e-4e04-a984-f5db9ad4a583",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-2,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9\n",
    ")\n",
    "optimizer = keras.optimizers.SGD(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef69a595-2286-4246-95f8-50f6dcfaee43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='mse'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36ec8fd6-717f-4a28-9852-ebc8414ba835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)                  │             \u001b[38;5;34m330\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)                  │           \u001b[38;5;34m3,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m56\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,466</span> (13.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,466\u001b[0m (13.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,466</span> (13.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,466\u001b[0m (13.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b466f21-4394-4ea8-90bc-7e5802eef631",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of the new training session...\n",
      "Training session 1/3\n",
      "Epoch 1/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 0.0168 - val_loss: 0.0028\n",
      "Epoch 2/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 3/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 4/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 5/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 6/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 7/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1ms/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 8/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 9/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 10/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 11/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 12/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 13/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 14/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 15/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 16/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 17/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 18/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 19/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 20/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 21/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 22/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 23/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 24/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 25/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 26/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 27/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 28/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 29/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 30/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 31/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 32/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 33/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 34/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 35/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 36/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 37/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 38/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 39/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 40/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 41/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 42/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 43/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 44/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 45/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 46/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 47/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 48/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 49/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 50/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "\n",
      "\n",
      "Start of the new training session...\n",
      "Training session 2/3\n",
      "Epoch 1/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 2/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 3/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 4/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 5/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 6/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 7/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 8/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 9/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 10/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 11/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 12/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 13/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 14/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 15/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 16/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 17/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 18/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 19/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 20/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 21/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 22/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 23/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 24/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 25/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 26/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 27/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 28/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 29/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 30/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 31/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 32/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 33/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 34/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 35/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 36/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 37/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 38/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 39/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 40/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 41/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 42/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 43/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 44/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 45/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 46/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 47/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 48/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 49/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 50/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "\n",
      "\n",
      "Start of the new training session...\n",
      "Training session 3/3\n",
      "Epoch 1/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 2/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 3/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 4/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 5/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 6/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 7/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 8/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 9/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 10/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 11/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 12/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 13/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 14/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 15/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 16/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 17/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 18/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 19/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 20/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 21/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 22/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 23/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 24/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 25/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 26/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 27/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 28/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 29/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 30/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 31/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 32/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 33/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 34/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 35/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 36/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 37/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 38/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 39/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 40/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 41/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 42/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 43/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 44/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 45/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 46/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 47/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 48/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 49/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 50/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in range(no_training):\n",
    "    print(f'Start of the new training session...')\n",
    "    print(f'Training session {t+1}/{no_training}')\n",
    "    history = model.fit(\n",
    "        normalized_X_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=mini_batch_size,\n",
    "        validation_data=(\n",
    "            normalized_X_val, \n",
    "            y_val\n",
    "        ),\n",
    "        verbose=1\n",
    "    )\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9549cbbc-041f-48ee-9843-635120c26ba4",
   "metadata": {},
   "source": [
    "# Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b1b908c-4ce6-4ee9-bd91-1fb1a2ef41f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\virtualenv\\myenv\\Lib\\site-packages\\keras\\src\\activations\\__init__.py:54: UserWarning: The object being serialized includes a `lambda`. This is unsafe. In order to reload the object, you will have to pass `safe_mode=False` to the loading function. Please avoid using `lambda` in the future, and use named Python functions instead. This is the `lambda` being serialized:     layers.Dense(no_responses, activation=lambda x: keras.backend.clip(x, 0, 1))\n",
      "\n",
      "  fn_config = serialization_lib.serialize_keras_object(activation)\n"
     ]
    }
   ],
   "source": [
    "model_path = f'./models/dl/soc_estimation_dl.keras'\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72886eb-3e53-4630-a691-d20f65ac6bfe",
   "metadata": {},
   "source": [
    "# Model History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1fb22322-e2d1-461f-b700-32ce0cd96676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36e3bd7-8b1b-48ad-a8d9-db78d65c58e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
