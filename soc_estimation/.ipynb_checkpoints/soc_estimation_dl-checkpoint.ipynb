{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc0fb09c-5748-4bb0-a640-cde28de380c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in d:\\virtualenv\\myenv\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (70.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in d:\\virtualenv\\myenv\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in d:\\virtualenv\\myenv\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in d:\\virtualenv\\myenv\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\virtualenv\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\virtualenv\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\virtualenv\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\virtualenv\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2024.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\virtualenv\\myenv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\virtualenv\\myenv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e312a512-0373-4f02-acab-60115b88ad8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\giorg\\AppData\\Local\\Temp\\ipykernel_6268\\3326022288.py:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f46f174c-7918-458f-ac6d-079f5bdbe198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10002450037801798501\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e9eb670-162c-4028-9ff5-b7a962c4526d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\virtualenv\\myenv\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in d:\\virtualenv\\myenv\\lib\\site-packages (from pandas) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\virtualenv\\myenv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\virtualenv\\myenv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\virtualenv\\myenv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\virtualenv\\myenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f358af3-c925-4122-86a5-f7ea8bf6f1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in d:\\virtualenv\\myenv\\lib\\site-packages (3.9.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\virtualenv\\myenv\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\virtualenv\\myenv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from matplotlib) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\virtualenv\\myenv\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.23 in d:\\virtualenv\\myenv\\lib\\site-packages (from matplotlib) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in d:\\virtualenv\\myenv\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\virtualenv\\myenv\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\virtualenv\\myenv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\virtualenv\\myenv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6701d76-4b48-474b-b828-85e1c396cf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from config import Config\n",
    "from utils import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe268446-8845-454d-8d41-4ba18eaa94a4",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f181568a-b11c-4e52-9d3b-c1cb45956826",
   "metadata": {},
   "source": [
    "## Paths Declaration\n",
    "Qui, di seguito, vengono riportati i path relativi al dataset di training, validation e testing. In particolare, il dataset di validation coincide con il primo dataset di testing contenuto nella cartella './LGHG2@n10C_to_25degC/Test'. Infatti, all'interno della directory './LGHG2@n10C_to_25degC/Test' sono presenti 5 possibili insiemi di dati così da poter essere sfruttati durante il testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e9d8c39-735e-4b20-91e7-a05a4b424844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_dir = ['test', 'train', 'val']\n",
      "train_data_dir = ['TRAIN_LGHG2@n10degC_to_25degC_Norm_5Inputs.csv']\n",
      "val_data_dir = ['01_TEST_LGHG2@n10degC_Norm_(05_Inputs).csv', '02_TEST_LGHG2@0degC_Norm_(05_Inputs).csv', '03_TEST_LGHG2@10degC_Norm_(05_Inputs).csv', '04_TEST_LGHG2@25degC_Norm_(05_Inputs).csv']\n",
      "test_data_dir = ['01_TEST_LGHG2@n10degC_Norm_(05_Inputs).csv', '02_TEST_LGHG2@0degC_Norm_(05_Inputs).csv', '03_TEST_LGHG2@10degC_Norm_(05_Inputs).csv', '04_TEST_LGHG2@25degC_Norm_(05_Inputs).csv']\n"
     ]
    }
   ],
   "source": [
    "config = Config(\n",
    "    data_dir='./data',\n",
    "    train_data_subdir='train/',\n",
    "    val_data_subdir='test/',\n",
    "    test_data_subdir='test/'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dee037-7f18-4047-85cc-908f2db39220",
   "metadata": {},
   "source": [
    "# Data Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78a282f4-2653-4037-ac2b-75216df36724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V</th>\n",
       "      <th>I</th>\n",
       "      <th>Temp</th>\n",
       "      <th>V_avg</th>\n",
       "      <th>I_avg</th>\n",
       "      <th>SOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.385148</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.303101</td>\n",
       "      <td>0.385148</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.206417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.385152</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.304591</td>\n",
       "      <td>0.385150</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.206417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.385156</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.306081</td>\n",
       "      <td>0.385152</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.206417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.385160</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.307572</td>\n",
       "      <td>0.385154</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.206417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.385164</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.309062</td>\n",
       "      <td>0.385156</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.206417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669951</th>\n",
       "      <td>0.478843</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.008477</td>\n",
       "      <td>0.459558</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.283243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669952</th>\n",
       "      <td>0.478843</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.008477</td>\n",
       "      <td>0.459699</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.283243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669953</th>\n",
       "      <td>0.478843</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.008477</td>\n",
       "      <td>0.459839</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.283243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669954</th>\n",
       "      <td>0.478961</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.008477</td>\n",
       "      <td>0.459979</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.283243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669955</th>\n",
       "      <td>0.478961</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.008477</td>\n",
       "      <td>0.460117</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.283243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>669956 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               V        I      Temp     V_avg    I_avg       SOC\n",
       "0       0.385148  0.75102  0.303101  0.385148  0.75102  0.206417\n",
       "1       0.385152  0.75102  0.304591  0.385150  0.75102  0.206417\n",
       "2       0.385156  0.75102  0.306081  0.385152  0.75102  0.206417\n",
       "3       0.385160  0.75102  0.307572  0.385154  0.75102  0.206417\n",
       "4       0.385164  0.75102  0.309062  0.385156  0.75102  0.206417\n",
       "...          ...      ...       ...       ...      ...       ...\n",
       "669951  0.478843  0.75102  0.008477  0.459558  0.75102  0.283243\n",
       "669952  0.478843  0.75102  0.008477  0.459699  0.75102  0.283243\n",
       "669953  0.478843  0.75102  0.008477  0.459839  0.75102  0.283243\n",
       "669954  0.478961  0.75102  0.008477  0.459979  0.75102  0.283243\n",
       "669955  0.478961  0.75102  0.008477  0.460117  0.75102  0.283243\n",
       "\n",
       "[669956 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_filename = os.listdir(config.get_train_data_dir())[0]\n",
    "train_data_path = os.path.join(config.get_train_data_dir(), train_data_filename)\n",
    "\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8da13fa7-413c-411c-b816-064757dc8140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V', 'I', 'Temp', 'V_avg', 'I_avg', 'SOC'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ceb8e614-11b7-4453-a338-c71839d81f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(669956, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_data[['V', 'I', 'Temp', 'V_avg', 'I_avg']].values\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90a89c18-d17c-41e2-8361-caaa9921976f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38514793, 0.75102009, 0.30310108, 0.38514793, 0.75102009],\n",
       "       [0.38515183, 0.75102009, 0.30459129, 0.38514988, 0.75102009],\n",
       "       [0.38515573, 0.75102009, 0.3060815 , 0.38515183, 0.75102009],\n",
       "       ...,\n",
       "       [0.47884278, 0.75102009, 0.00847709, 0.45983939, 0.75102009],\n",
       "       [0.4789612 , 0.75102009, 0.00847709, 0.45997861, 0.75102009],\n",
       "       [0.4789612 , 0.75102009, 0.00847709, 0.46011672, 0.75102009]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e396bbb2-14c7-4637-8ad2-1d5170af5b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(669956,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train_data['SOC'].values\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fb36c47-8b7f-4ed9-b58b-c90413322b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20641667, 0.20641667, 0.20641667, ..., 0.28324333, 0.28324333,\n",
       "       0.28324333])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e343c7c-ffb1-40ae-a091-592fcc1f6fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V</th>\n",
       "      <th>I</th>\n",
       "      <th>Temp</th>\n",
       "      <th>V_avg</th>\n",
       "      <th>I_avg</th>\n",
       "      <th>SOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.966960</td>\n",
       "      <td>0.748900</td>\n",
       "      <td>0.920678</td>\n",
       "      <td>0.966960</td>\n",
       "      <td>0.748900</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.966020</td>\n",
       "      <td>0.746992</td>\n",
       "      <td>0.920677</td>\n",
       "      <td>0.966490</td>\n",
       "      <td>0.747946</td>\n",
       "      <td>0.999990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.965901</td>\n",
       "      <td>0.746992</td>\n",
       "      <td>0.917845</td>\n",
       "      <td>0.966294</td>\n",
       "      <td>0.747628</td>\n",
       "      <td>0.999983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.965783</td>\n",
       "      <td>0.747098</td>\n",
       "      <td>0.917845</td>\n",
       "      <td>0.966166</td>\n",
       "      <td>0.747496</td>\n",
       "      <td>0.999973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.746992</td>\n",
       "      <td>0.917845</td>\n",
       "      <td>0.966066</td>\n",
       "      <td>0.747395</td>\n",
       "      <td>0.999963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47512</th>\n",
       "      <td>0.298614</td>\n",
       "      <td>0.751020</td>\n",
       "      <td>0.926344</td>\n",
       "      <td>0.292723</td>\n",
       "      <td>0.751020</td>\n",
       "      <td>0.136623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47513</th>\n",
       "      <td>0.298614</td>\n",
       "      <td>0.751020</td>\n",
       "      <td>0.926344</td>\n",
       "      <td>0.292761</td>\n",
       "      <td>0.751020</td>\n",
       "      <td>0.136623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47514</th>\n",
       "      <td>0.298614</td>\n",
       "      <td>0.751020</td>\n",
       "      <td>0.926344</td>\n",
       "      <td>0.292798</td>\n",
       "      <td>0.751020</td>\n",
       "      <td>0.136623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47515</th>\n",
       "      <td>0.298614</td>\n",
       "      <td>0.751020</td>\n",
       "      <td>0.929177</td>\n",
       "      <td>0.292834</td>\n",
       "      <td>0.751020</td>\n",
       "      <td>0.136623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47516</th>\n",
       "      <td>0.298614</td>\n",
       "      <td>0.751020</td>\n",
       "      <td>0.929177</td>\n",
       "      <td>0.292871</td>\n",
       "      <td>0.751020</td>\n",
       "      <td>0.136623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47517 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V         I      Temp     V_avg     I_avg       SOC\n",
       "0      0.966960  0.748900  0.920678  0.966960  0.748900  1.000000\n",
       "1      0.966020  0.746992  0.920677  0.966490  0.747946  0.999990\n",
       "2      0.965901  0.746992  0.917845  0.966294  0.747628  0.999983\n",
       "3      0.965783  0.747098  0.917845  0.966166  0.747496  0.999973\n",
       "4      0.965665  0.746992  0.917845  0.966066  0.747395  0.999963\n",
       "...         ...       ...       ...       ...       ...       ...\n",
       "47512  0.298614  0.751020  0.926344  0.292723  0.751020  0.136623\n",
       "47513  0.298614  0.751020  0.926344  0.292761  0.751020  0.136623\n",
       "47514  0.298614  0.751020  0.926344  0.292798  0.751020  0.136623\n",
       "47515  0.298614  0.751020  0.929177  0.292834  0.751020  0.136623\n",
       "47516  0.298614  0.751020  0.929177  0.292871  0.751020  0.136623\n",
       "\n",
       "[47517 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data_filename = os.listdir(config.get_val_data_dir())[3]\n",
    "val_data_path = os.path.join(config.get_val_data_dir(), val_data_filename)\n",
    "\n",
    "val_data = pd.read_csv(val_data_path)\n",
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9a91c26-3722-4049-b44b-40791e282e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = val_data[['V', 'I', 'Temp', 'V_avg', 'I_avg']].values\n",
    "y_val = val_data['SOC'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc9eb9e-1cd3-4898-89de-f4784ea975fa",
   "metadata": {},
   "source": [
    "## Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efd863c2-d65a-4f68-bb78-cd7d4469c68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.63365322,  1.        , -1.        , -0.63365322,  1.        ],\n",
       "       [-0.63908898,  1.        , -1.        , -0.63909772,  1.        ],\n",
       "       [-0.64456116,  1.        , -1.        , -0.64457869,  1.        ],\n",
       "       ...,\n",
       "       [ 0.26690492,  1.        , -1.        ,  0.21572031,  1.        ],\n",
       "       [ 0.26722387,  1.        , -1.        ,  0.21609528,  1.        ],\n",
       "       [ 0.26722387,  1.        , -1.        ,  0.21646728,  1.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_X_train = normalize(X_train)\n",
    "normalized_X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24edad19-e5ed-4041-9be3-858ee2269ffe",
   "metadata": {},
   "source": [
    "# FNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155955d9-48e4-4d9b-a472-952587ee5cfb",
   "metadata": {},
   "source": [
    "## Training Parameters Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0f4f886-17d5-4564-b435-93a3fd59d796",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_features = 5  # Number of inputs features (variables: V, I, Temp, V_avg, I_avg)\n",
    "no_responses = 1  # Number of outputs (SOC)\n",
    "no_hidden_units = 55  # Number of optimal hidden units 'N', where each hidden unit for FNN represents a Neuron.\n",
    "\n",
    "epochs = 50 # Number of epochs\n",
    "no_training = 3 # Number of training execution\n",
    "learn_rate_drop_period = 1000\n",
    "initial_learn_rate = 0.01\n",
    "learn_rate_drop_factor = 0.1\n",
    "validation_frequency = 10\n",
    "mini_batch_size = 32\n",
    "l2_regularization = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e14f30-a647-4edf-8793-e000ca9d2c8c",
   "metadata": {},
   "source": [
    "## FNN Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c60e609f-9a77-4a52-8e5b-1b36481370f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cacd8998-0144-4842-b32a-3ecc1a823893",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainableNormalization(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(TrainableNormalization, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.mean = self.add_weight(\n",
    "            name='mean', \n",
    "            shape=(input_shape[-1],),\n",
    "            initializer='zeros', \n",
    "            trainable=True\n",
    "        )\n",
    "        self.std = self.add_weight(\n",
    "            name='std', \n",
    "            shape=(input_shape[-1],),\n",
    "            initializer='ones', \n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return (inputs - self.mean) / (self.std + keras.backend.epsilon())\n",
    "\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(no_features,)),\n",
    "    layers.Dense(no_hidden_units, activation='tanh'),\n",
    "    layers.Dense(no_hidden_units, activation=layers.LeakyReLU(negative_slope=0.3)),\n",
    "    layers.Dense(no_responses, activation=lambda x: keras.backend.clip(x, 0, 1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2be3f69-137e-4e04-a984-f5db9ad4a583",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-2,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9\n",
    ")\n",
    "optimizer = keras.optimizers.SGD(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef69a595-2286-4246-95f8-50f6dcfaee43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='mse'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36ec8fd6-717f-4a28-9852-ebc8414ba835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)                  │             \u001b[38;5;34m330\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)                  │           \u001b[38;5;34m3,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m56\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,466</span> (13.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,466\u001b[0m (13.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,466</span> (13.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,466\u001b[0m (13.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b466f21-4394-4ea8-90bc-7e5802eef631",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0182 - val_loss: 0.0024\n",
      "Epoch 2/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 3/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 4/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 5/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 6/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 7/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 8/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 9/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 10/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 11/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 12/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 13/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 14/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 15/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 16/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 17/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 18/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 19/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 3ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 20/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 21/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 22/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 23/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 24/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 25/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 26/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 27/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 28/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 29/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 30/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 3ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 31/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 32/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 33/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 34/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 35/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 36/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 37/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 38/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 39/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 999us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 40/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 41/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 42/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 43/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 44/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 45/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 46/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 47/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 48/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 49/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 50/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 1/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 2/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 3/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 4/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 5/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 6/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 7/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 8/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 9/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 10/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 11/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 12/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 13/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 14/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 15/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 16/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 17/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 18/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 19/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 20/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 21/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 22/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 23/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 24/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 25/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 26/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 27/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 28/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 29/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 30/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 31/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 32/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 33/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 34/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 35/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 36/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 37/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 38/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 39/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 40/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 41/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 42/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 43/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 44/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 45/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 46/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 47/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 48/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 49/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 50/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 1/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 2/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 3/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 4/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 5/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 6/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 7/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 8/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 9/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 10/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 11/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 12/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 13/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 14/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 15/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 16/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 17/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 18/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 19/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 20/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 21/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 22/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 23/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 24/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 25/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 26/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 27/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 28/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 29/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 30/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 31/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 32/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 33/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 34/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 35/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 36/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 37/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 38/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 39/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 40/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 41/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 42/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 43/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 44/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 45/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 46/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 47/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 48/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 49/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 50/50\n",
      "\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0015\n"
     ]
    }
   ],
   "source": [
    "for t in range(no_training):\n",
    "    history = model.fit(\n",
    "        normalized_X_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=mini_batch_size,\n",
    "        validation_data=(\n",
    "            X_val, \n",
    "            y_val\n",
    "        ),\n",
    "        verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9549cbbc-041f-48ee-9843-635120c26ba4",
   "metadata": {},
   "source": [
    "# Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b1b908c-4ce6-4ee9-bd91-1fb1a2ef41f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\virtualenv\\myenv\\Lib\\site-packages\\keras\\src\\activations\\__init__.py:54: UserWarning: The object being serialized includes a `lambda`. This is unsafe. In order to reload the object, you will have to pass `safe_mode=False` to the loading function. Please avoid using `lambda` in the future, and use named Python functions instead. This is the `lambda` being serialized:     layers.Dense(no_responses, activation=lambda x: keras.backend.clip(x, 0, 1))\n",
      "\n",
      "  fn_config = serialization_lib.serialize_keras_object(activation)\n"
     ]
    }
   ],
   "source": [
    "model_path = f'./models/dl/soc_estimation_dl.keras'\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72886eb-3e53-4630-a691-d20f65ac6bfe",
   "metadata": {},
   "source": [
    "# Model History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1fb22322-e2d1-461f-b700-32ce0cd96676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36e3bd7-8b1b-48ad-a8d9-db78d65c58e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
