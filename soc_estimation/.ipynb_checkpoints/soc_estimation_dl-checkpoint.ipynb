{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc0fb09c-5748-4bb0-a640-cde28de380c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in d:\\virtualenv\\myenv\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (70.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in d:\\virtualenv\\myenv\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in d:\\virtualenv\\myenv\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in d:\\virtualenv\\myenv\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\virtualenv\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\virtualenv\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\virtualenv\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\virtualenv\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2024.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\virtualenv\\myenv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\virtualenv\\myenv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\virtualenv\\myenv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e312a512-0373-4f02-acab-60115b88ad8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\giorg\\AppData\\Local\\Temp\\ipykernel_11240\\3326022288.py:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f46f174c-7918-458f-ac6d-079f5bdbe198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 2186686193332498869\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e9eb670-162c-4028-9ff5-b7a962c4526d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\virtualenv\\myenv\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in d:\\virtualenv\\myenv\\lib\\site-packages (from pandas) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\virtualenv\\myenv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\virtualenv\\myenv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\virtualenv\\myenv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\virtualenv\\myenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f358af3-c925-4122-86a5-f7ea8bf6f1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in d:\\virtualenv\\myenv\\lib\\site-packages (3.9.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\virtualenv\\myenv\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\virtualenv\\myenv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from matplotlib) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\virtualenv\\myenv\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.23 in d:\\virtualenv\\myenv\\lib\\site-packages (from matplotlib) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\virtualenv\\myenv\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in d:\\virtualenv\\myenv\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\virtualenv\\myenv\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\virtualenv\\myenv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\virtualenv\\myenv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6701d76-4b48-474b-b828-85e1c396cf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from config import Config\n",
    "from utils import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe268446-8845-454d-8d41-4ba18eaa94a4",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f181568a-b11c-4e52-9d3b-c1cb45956826",
   "metadata": {},
   "source": [
    "## Paths Declaration\n",
    "Qui, di seguito, vengono riportati i path relativi al dataset di training, validation e testing. In particolare, il dataset di validation coincide con il primo dataset di testing contenuto nella cartella './LGHG2@n10C_to_25degC/Test'. Infatti, all'interno della directory './LGHG2@n10C_to_25degC/Test' sono presenti 5 possibili insiemi di dati così da poter essere sfruttati durante il testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e9d8c39-735e-4b20-91e7-a05a4b424844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_dir = ['test', 'train', 'val']\n",
      "train_data_dir = ['TRAIN_LGHG2@n10degC_to_25degC_Norm_5Inputs.csv']\n",
      "val_data_dir = ['01_TEST_LGHG2@n10degC_Norm_(05_Inputs).csv', '02_TEST_LGHG2@0degC_Norm_(05_Inputs).csv', '03_TEST_LGHG2@10degC_Norm_(05_Inputs).csv', '04_TEST_LGHG2@25degC_Norm_(05_Inputs).csv']\n",
      "test_data_dir = ['01_TEST_LGHG2@n10degC_Norm_(05_Inputs).csv', '02_TEST_LGHG2@0degC_Norm_(05_Inputs).csv', '03_TEST_LGHG2@10degC_Norm_(05_Inputs).csv', '04_TEST_LGHG2@25degC_Norm_(05_Inputs).csv']\n"
     ]
    }
   ],
   "source": [
    "config = Config(\n",
    "    data_dir='./data',\n",
    "    train_data_subdir='train/',\n",
    "    val_data_subdir='test/',\n",
    "    test_data_subdir='test/'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dee037-7f18-4047-85cc-908f2db39220",
   "metadata": {},
   "source": [
    "# Data Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78a282f4-2653-4037-ac2b-75216df36724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V</th>\n",
       "      <th>I</th>\n",
       "      <th>Temp</th>\n",
       "      <th>V_avg</th>\n",
       "      <th>I_avg</th>\n",
       "      <th>SOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.385148</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.303101</td>\n",
       "      <td>0.385148</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.206417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.385152</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.304591</td>\n",
       "      <td>0.385150</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.206417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.385156</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.306081</td>\n",
       "      <td>0.385152</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.206417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.385160</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.307572</td>\n",
       "      <td>0.385154</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.206417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.385164</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.309062</td>\n",
       "      <td>0.385156</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.206417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669951</th>\n",
       "      <td>0.478843</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.008477</td>\n",
       "      <td>0.459558</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.283243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669952</th>\n",
       "      <td>0.478843</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.008477</td>\n",
       "      <td>0.459699</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.283243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669953</th>\n",
       "      <td>0.478843</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.008477</td>\n",
       "      <td>0.459839</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.283243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669954</th>\n",
       "      <td>0.478961</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.008477</td>\n",
       "      <td>0.459979</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.283243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669955</th>\n",
       "      <td>0.478961</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.008477</td>\n",
       "      <td>0.460117</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.283243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>669956 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               V        I      Temp     V_avg    I_avg       SOC\n",
       "0       0.385148  0.75102  0.303101  0.385148  0.75102  0.206417\n",
       "1       0.385152  0.75102  0.304591  0.385150  0.75102  0.206417\n",
       "2       0.385156  0.75102  0.306081  0.385152  0.75102  0.206417\n",
       "3       0.385160  0.75102  0.307572  0.385154  0.75102  0.206417\n",
       "4       0.385164  0.75102  0.309062  0.385156  0.75102  0.206417\n",
       "...          ...      ...       ...       ...      ...       ...\n",
       "669951  0.478843  0.75102  0.008477  0.459558  0.75102  0.283243\n",
       "669952  0.478843  0.75102  0.008477  0.459699  0.75102  0.283243\n",
       "669953  0.478843  0.75102  0.008477  0.459839  0.75102  0.283243\n",
       "669954  0.478961  0.75102  0.008477  0.459979  0.75102  0.283243\n",
       "669955  0.478961  0.75102  0.008477  0.460117  0.75102  0.283243\n",
       "\n",
       "[669956 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_filename = os.listdir(config.get_train_data_dir())[0]\n",
    "train_data_path = os.path.join(config.get_train_data_dir(), train_data_filename)\n",
    "\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8da13fa7-413c-411c-b816-064757dc8140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V', 'I', 'Temp', 'V_avg', 'I_avg', 'SOC'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ceb8e614-11b7-4453-a338-c71839d81f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(669956, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_data[['V', 'I', 'Temp', 'V_avg', 'I_avg']].values\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90a89c18-d17c-41e2-8361-caaa9921976f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38514793, 0.75102009, 0.30310108, 0.38514793, 0.75102009],\n",
       "       [0.38515183, 0.75102009, 0.30459129, 0.38514988, 0.75102009],\n",
       "       [0.38515573, 0.75102009, 0.3060815 , 0.38515183, 0.75102009],\n",
       "       ...,\n",
       "       [0.47884278, 0.75102009, 0.00847709, 0.45983939, 0.75102009],\n",
       "       [0.4789612 , 0.75102009, 0.00847709, 0.45997861, 0.75102009],\n",
       "       [0.4789612 , 0.75102009, 0.00847709, 0.46011672, 0.75102009]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e396bbb2-14c7-4637-8ad2-1d5170af5b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(669956,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train_data['SOC'].values\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fb36c47-8b7f-4ed9-b58b-c90413322b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20641667, 0.20641667, 0.20641667, ..., 0.28324333, 0.28324333,\n",
       "       0.28324333])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e343c7c-ffb1-40ae-a091-592fcc1f6fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V</th>\n",
       "      <th>I</th>\n",
       "      <th>Temp</th>\n",
       "      <th>V_avg</th>\n",
       "      <th>I_avg</th>\n",
       "      <th>SOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.966960</td>\n",
       "      <td>0.748900</td>\n",
       "      <td>0.920678</td>\n",
       "      <td>0.966960</td>\n",
       "      <td>0.748900</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.966020</td>\n",
       "      <td>0.746992</td>\n",
       "      <td>0.920677</td>\n",
       "      <td>0.966490</td>\n",
       "      <td>0.747946</td>\n",
       "      <td>0.999990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.965901</td>\n",
       "      <td>0.746992</td>\n",
       "      <td>0.917845</td>\n",
       "      <td>0.966294</td>\n",
       "      <td>0.747628</td>\n",
       "      <td>0.999983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.965783</td>\n",
       "      <td>0.747098</td>\n",
       "      <td>0.917845</td>\n",
       "      <td>0.966166</td>\n",
       "      <td>0.747496</td>\n",
       "      <td>0.999973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.746992</td>\n",
       "      <td>0.917845</td>\n",
       "      <td>0.966066</td>\n",
       "      <td>0.747395</td>\n",
       "      <td>0.999963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47512</th>\n",
       "      <td>0.298614</td>\n",
       "      <td>0.751020</td>\n",
       "      <td>0.926344</td>\n",
       "      <td>0.292723</td>\n",
       "      <td>0.751020</td>\n",
       "      <td>0.136623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47513</th>\n",
       "      <td>0.298614</td>\n",
       "      <td>0.751020</td>\n",
       "      <td>0.926344</td>\n",
       "      <td>0.292761</td>\n",
       "      <td>0.751020</td>\n",
       "      <td>0.136623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47514</th>\n",
       "      <td>0.298614</td>\n",
       "      <td>0.751020</td>\n",
       "      <td>0.926344</td>\n",
       "      <td>0.292798</td>\n",
       "      <td>0.751020</td>\n",
       "      <td>0.136623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47515</th>\n",
       "      <td>0.298614</td>\n",
       "      <td>0.751020</td>\n",
       "      <td>0.929177</td>\n",
       "      <td>0.292834</td>\n",
       "      <td>0.751020</td>\n",
       "      <td>0.136623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47516</th>\n",
       "      <td>0.298614</td>\n",
       "      <td>0.751020</td>\n",
       "      <td>0.929177</td>\n",
       "      <td>0.292871</td>\n",
       "      <td>0.751020</td>\n",
       "      <td>0.136623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47517 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V         I      Temp     V_avg     I_avg       SOC\n",
       "0      0.966960  0.748900  0.920678  0.966960  0.748900  1.000000\n",
       "1      0.966020  0.746992  0.920677  0.966490  0.747946  0.999990\n",
       "2      0.965901  0.746992  0.917845  0.966294  0.747628  0.999983\n",
       "3      0.965783  0.747098  0.917845  0.966166  0.747496  0.999973\n",
       "4      0.965665  0.746992  0.917845  0.966066  0.747395  0.999963\n",
       "...         ...       ...       ...       ...       ...       ...\n",
       "47512  0.298614  0.751020  0.926344  0.292723  0.751020  0.136623\n",
       "47513  0.298614  0.751020  0.926344  0.292761  0.751020  0.136623\n",
       "47514  0.298614  0.751020  0.926344  0.292798  0.751020  0.136623\n",
       "47515  0.298614  0.751020  0.929177  0.292834  0.751020  0.136623\n",
       "47516  0.298614  0.751020  0.929177  0.292871  0.751020  0.136623\n",
       "\n",
       "[47517 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data_filename = os.listdir(config.get_val_data_dir())[3]\n",
    "val_data_path = os.path.join(config.get_val_data_dir(), val_data_filename)\n",
    "\n",
    "val_data = pd.read_csv(val_data_path)\n",
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9a91c26-3722-4049-b44b-40791e282e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = val_data[['V', 'I', 'Temp', 'V_avg', 'I_avg']].values\n",
    "y_val = val_data['SOC'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc9eb9e-1cd3-4898-89de-f4784ea975fa",
   "metadata": {},
   "source": [
    "## Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efd863c2-d65a-4f68-bb78-cd7d4469c68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.63365322,  1.        , -1.        , -0.63365322,  1.        ],\n",
       "       [-0.63908898,  1.        , -1.        , -0.63909772,  1.        ],\n",
       "       [-0.64456116,  1.        , -1.        , -0.64457869,  1.        ],\n",
       "       ...,\n",
       "       [ 0.26690492,  1.        , -1.        ,  0.21572031,  1.        ],\n",
       "       [ 0.26722387,  1.        , -1.        ,  0.21609528,  1.        ],\n",
       "       [ 0.26722387,  1.        , -1.        ,  0.21646728,  1.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_X_train = normalize(X_train)\n",
    "normalized_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "283ee538-242a-4c7a-a9d6-d20d5aab6809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -1.        ,  0.57551079,  1.        , -1.        ],\n",
       "       [ 0.99571585, -1.        ,  0.58256774,  1.        , -0.99130679],\n",
       "       [ 0.99642139, -1.        ,  0.55815534,  1.        , -0.99419975],\n",
       "       ...,\n",
       "       [-0.98163938,  0.44653221,  1.        , -1.        ,  0.44653221],\n",
       "       [-0.98183573,  0.44006032,  1.        , -1.        ,  0.44006032],\n",
       "       [-0.98194943,  0.44002819,  1.        , -1.        ,  0.44002819]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_X_val = normalize(X_val)\n",
    "normalized_X_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24edad19-e5ed-4041-9be3-858ee2269ffe",
   "metadata": {},
   "source": [
    "# FNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155955d9-48e4-4d9b-a472-952587ee5cfb",
   "metadata": {},
   "source": [
    "## Training Parameters Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0f4f886-17d5-4564-b435-93a3fd59d796",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_features = 5  # Number of inputs features (variables: V, I, Temp, V_avg, I_avg)\n",
    "no_responses = 1  # Number of outputs (SOC)\n",
    "no_hidden_units = 55  # Number of optimal hidden units 'N', where each hidden unit for FNN represents a Neuron.\n",
    "\n",
    "epochs = 50 # Number of epochs\n",
    "no_training = 3 # Number of training execution\n",
    "mini_batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e14f30-a647-4edf-8793-e000ca9d2c8c",
   "metadata": {},
   "source": [
    "## FNN Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c60e609f-9a77-4a52-8e5b-1b36481370f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from custom import CustomLeakyReLU, CustomClippedReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cacd8998-0144-4842-b32a-3ecc1a823893",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(no_features,)),\n",
    "    layers.Dense(\n",
    "        no_hidden_units,\n",
    "        activation=keras.activations.tanh\n",
    "    ),\n",
    "    layers.Dense(\n",
    "        no_hidden_units,\n",
    "        activation=CustomLeakyReLU(negative_slope=0.3)\n",
    "    ),\n",
    "    layers.Dense(\n",
    "        no_responses,\n",
    "        activation=CustomClippedReLU()\n",
    "    )\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2be3f69-137e-4e04-a984-f5db9ad4a583",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.01,\n",
    "    decay_steps=20000,\n",
    "    decay_rate=0.9,\n",
    "    staircase=False\n",
    ")\n",
    "\n",
    "optimizer = keras.optimizers.SGD(\n",
    "    learning_rate=lr_schedule\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef69a595-2286-4246-95f8-50f6dcfaee43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='mse'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36ec8fd6-717f-4a28-9852-ebc8414ba835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)                  │             \u001b[38;5;34m330\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)                  │           \u001b[38;5;34m3,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m56\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,466</span> (13.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,466\u001b[0m (13.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,466</span> (13.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,466\u001b[0m (13.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b466f21-4394-4ea8-90bc-7e5802eef631",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of the new training session...\n",
      "Training session 1/3\n",
      "Epoch 1/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 0.0154 - val_loss: 0.0034\n",
      "Epoch 2/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 3/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 4/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 5/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 6/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 7/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 8/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 9/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 10/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 11/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 12/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 13/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 14/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 15/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 16/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 17/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 18/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 19/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 20/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 21/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 22/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 23/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 24/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 25/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 26/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 27/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 28/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 29/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 30/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 31/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 32/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 33/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 34/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 35/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 36/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 37/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 38/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 39/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 40/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 41/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 42/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 43/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 44/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 45/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 46/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 47/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 48/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 49/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 50/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "\n",
      "\n",
      "Start of the new training session...\n",
      "Training session 2/3\n",
      "Epoch 1/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 2/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 3/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 4/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 5/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 6/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 7/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 8/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 9/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 10/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 11/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 12/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 13/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 14/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 15/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 16/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 17/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 18/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 19/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 20/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 21/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 22/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 23/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 24/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 25/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 26/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 27/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 28/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 29/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 30/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 31/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 32/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 33/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 34/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 35/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 36/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 37/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 38/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 39/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 40/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 41/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 42/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 43/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 44/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 45/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 46/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 47/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 48/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 49/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 50/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "\n",
      "\n",
      "Start of the new training session...\n",
      "Training session 3/3\n",
      "Epoch 1/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 2/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 3/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 4/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 5/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 6/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 7/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 8/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 9/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 10/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 11/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 12/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 13/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 14/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 15/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 16/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 17/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 18/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 19/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 20/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 21/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 22/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 23/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 24/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 25/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 26/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 27/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 28/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 29/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 30/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 31/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 32/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 33/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 34/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 35/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 36/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 37/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 38/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 39/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 40/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 41/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 42/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 43/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 44/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 45/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 46/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 47/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 48/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 49/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 50/50\n",
      "\u001b[1m10469/10469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in range(no_training):\n",
    "    print(f'Start of the new training session...')\n",
    "    print(f'Training session {t+1}/{no_training}')\n",
    "    history = model.fit(\n",
    "        x=normalized_X_train,\n",
    "        y=y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=mini_batch_size,\n",
    "        validation_data=(\n",
    "            normalized_X_val, \n",
    "            y_val\n",
    "        ),\n",
    "        verbose=1,\n",
    "    )\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9549cbbc-041f-48ee-9843-635120c26ba4",
   "metadata": {},
   "source": [
    "# Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b1b908c-4ce6-4ee9-bd91-1fb1a2ef41f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './models/dl/soc_estimation_dl.keras'\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72886eb-3e53-4630-a691-d20f65ac6bfe",
   "metadata": {},
   "source": [
    "# Model History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7bd8beb-3f8e-4f21-bdd2-22472b2cb37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.001983</td>\n",
       "      <td>0.001228</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.001983</td>\n",
       "      <td>0.001228</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.001983</td>\n",
       "      <td>0.001228</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.001983</td>\n",
       "      <td>0.001228</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.001983</td>\n",
       "      <td>0.001228</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  val_loss  epoch\n",
       "45  0.001983  0.001228     45\n",
       "46  0.001983  0.001228     46\n",
       "47  0.001983  0.001228     47\n",
       "48  0.001983  0.001228     48\n",
       "49  0.001983  0.001228     49"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fb22322-e2d1-461f-b700-32ce0cd96676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
